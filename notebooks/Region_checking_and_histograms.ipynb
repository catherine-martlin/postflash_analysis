{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece07e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from astropy.nddata import Cutout2D\n",
    "from bokeh.io import output_file, output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, Range1d\n",
    "from bokeh.layouts import row, column, gridplot\n",
    "from bokeh.models.widgets import Tabs, Panel\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Determine where the visualization will be rendered\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define all Paths here: \n",
    "#biyearly_image = '/Users/cmartlin/Desktop/postflash_2022_work/2018-2019_test_01_26_2022_idle02ayq_flc.fits'\n",
    "#current_image = '/Users/cmartlin/Desktop/postflash_2022_work/idle02ayq/idle02ayq_flc.fits'\n",
    "#yearly_image = '/Users/cmartlin/Desktop/postflash_2022_work/2018_yearly_low_10_18_2022_idn011e6s_flc.fits'\n",
    "\n",
    "#updated_yearly = glob.glob('/Users/cmartlin/Desktop/postflash_2022_work/*10_18*')\n",
    "#science_pipeline = glob.glob('/Users/cmartlin/Desktop/postflash_2022_work/i*/i*flc.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define all Paths here: \n",
    "biyearly_image = '2022_ISR_testing_data/2018-2019_test_01_26_2022_idle02ayq_flc.fits'\n",
    "current_image = '2022_ISR_testing_data/idle02ayq_flc.fits'\n",
    "yearly_image = '2022_ISR_testing_data/2018_yearly_low_10_18_2022_idn011e6s_flc.fits'\n",
    "\n",
    "updated_yearly = glob.glob('2022_ISR_testing_data/*10_18*')\n",
    "science_pipeline = glob.glob('2022_ISR_testing_data/i*flc.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the testing data rootnames used in function:\n",
    "for f in updated_yearly: \n",
    "    print(f[-18:])\n",
    "    \n",
    "#Checking for year length - if this needs to change, update in function below: \n",
    "for f in updated_yearly: \n",
    "    print(f[22:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the science data rootnames used in function:\n",
    "for f in science_pipeline: \n",
    "    print(f[-18:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_databases(input_data, positions_list):\n",
    "    size = (101, 101)\n",
    "    \n",
    "    min_pos = []\n",
    "    max_pos = []\n",
    "    mean_pos = []\n",
    "    median_pos = []\n",
    "    std_pos = []\n",
    "    \n",
    "    for f in input_data: \n",
    "        image_data = fits.getdata(f,1)\n",
    "        means = []\n",
    "        maxes = []\n",
    "        mins = []\n",
    "        medians = []\n",
    "        stdevs = []\n",
    "        for p in positions_list: \n",
    "            cutout = Cutout2D(image_data, p, size)\n",
    "            cutout1 = cutout.data\n",
    "            mins.append(np.min(cutout1))\n",
    "            maxes.append(np.max(cutout1))\n",
    "            means.append(np.mean(cutout1))\n",
    "            medians.append(np.median(cutout1))\n",
    "            stdevs.append(np.std(cutout1))\n",
    "        std_pos.append(stdevs)\n",
    "        min_pos.append(mins)\n",
    "        max_pos.append(maxes)\n",
    "        mean_pos.append(means)\n",
    "        median_pos.append(medians)\n",
    "    filenames = []\n",
    "    years = []\n",
    "\n",
    "    for f in input_data:\n",
    "        filenames.append(f[-18:])\n",
    "        years.append(f[44:48]) \n",
    "\n",
    "    positions = [220, 900, 2100, 3500, 3600]\n",
    "    positions_pipeline = ['pipe_220', 'pipe_900', 'pipe_2100', 'pipe_3500', \n",
    "                          'pipe_3600']\n",
    "       \n",
    "    # Condition to check if there is a year in the filename:\n",
    "    if (years[0].isnumeric()) == True: \n",
    "        stdev_df = pd.DataFrame(std_pos, columns=positions, dtype = float, \n",
    "                                index=filenames)\n",
    "        min_df = pd.DataFrame(min_pos, columns=positions, dtype = float, \n",
    "                                    index=filenames)\n",
    "        max_df = pd.DataFrame(max_pos, columns=positions, dtype = float, \n",
    "                                    index=filenames)\n",
    "        mean_df = pd.DataFrame(mean_pos, columns=positions, dtype = float, \n",
    "                                    index=filenames)\n",
    "        median_df = pd.DataFrame(median_pos, columns=positions, dtype = float, \n",
    "                                    index=filenames)\n",
    "        years = pd.DataFrame(years, index=filenames)\n",
    "        stdev_df = pd.concat([stdev_df, years],1)\n",
    "        min_df = pd.concat([min_df, years],1)\n",
    "        max_df = pd.concat([max_df, years],1)\n",
    "        mean_df = pd.concat([mean_df, years],1)\n",
    "        median_df = pd.concat([median_df, years],1)\n",
    "    else:\n",
    "        stdev_df = pd.DataFrame(std_pos, columns=positions_pipeline, \n",
    "                                dtype = float, index=filenames)\n",
    "        min_df = pd.DataFrame(min_pos, columns=positions_pipeline, \n",
    "                              dtype = float, index=filenames)\n",
    "        max_df = pd.DataFrame(max_pos, columns=positions_pipeline, \n",
    "                              dtype = float, index=filenames)\n",
    "        mean_df = pd.DataFrame(mean_pos, columns=positions_pipeline, \n",
    "                               dtype = float, index=filenames)\n",
    "        median_df = pd.DataFrame(median_pos, columns=positions_pipeline, \n",
    "                                 dtype = float, index=filenames)\n",
    "    \n",
    "    #return stdev_df, min_df, max_df, mean_df, median_df\n",
    "    return stdev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_list = [(220, 160), (900,700), (2100,1100), (3500,300), (3600,1700)]\n",
    "\n",
    "stdev_yearly = create_databases(updated_yearly, positions_list)\n",
    "stdev_pipeline = create_databases(science_pipeline, positions_list)\n",
    "\n",
    "combine_by_file = pd.concat([stdev_yearly,stdev_pipeline],1)\n",
    "stdev_yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_by_file['220_norm'] = (combine_by_file[220] - combine_by_file['pipe_220']) / combine_by_file['pipe_220']\n",
    "combine_by_file['900_norm'] = (combine_by_file[900] - combine_by_file['pipe_900']) / combine_by_file['pipe_900']\n",
    "combine_by_file['2100_norm'] = (combine_by_file[2100] - combine_by_file['pipe_2100']) / combine_by_file['pipe_2100']\n",
    "combine_by_file['3500_norm'] = (combine_by_file[3500] - combine_by_file['pipe_3500']) / combine_by_file['pipe_3500']\n",
    "combine_by_file['3600_norm'] = (combine_by_file[3600] - combine_by_file['pipe_3600']) / combine_by_file['pipe_3600']\n",
    "\n",
    "stdev_sorted_by_year = combine_by_file.sort_values(by=[0])\n",
    "stdev_sorted_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list([2012,2013,2014,2015,2016,2017,2018,2019,2020,2021])\n",
    "#x2 = list([5,1,4,6,3,2])\n",
    "x3 = list([1, 2, 3, 4, 5, 6])\n",
    "y = list(sorted_by_year['220_norm'].values)\n",
    "y2 = list(sorted_by_year['900_norm'].values)\n",
    "y3 = list(sorted_by_year['2100_norm'].values)\n",
    "y4 = list(sorted_by_year['3500_norm'].values)\n",
    "y5 = list(sorted_by_year['3600_norm'].values)\n",
    "\n",
    "p = figure(title = 'Checking Stdev')\n",
    "p.line(x,y)\n",
    "p.line(x,y2)\n",
    "p.line(x,y3)\n",
    "p.line(x,y4)\n",
    "p.line(x,y5)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_biyearly = fits.getdata(biyearly_image,1)\n",
    "image_curr = fits.getdata(current_image,1)\n",
    "image_yearly = fits.getdata(yearly_image,1)\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "plt.hist(image_biyearly.flatten(),alpha=0.5, range=(-20,20), bins=100)\n",
    "plt.hist(image_curr.flatten(),alpha=0.5, range=(-20,20), bins=100)\n",
    "plt.hist(image_yearly.flatten(),alpha=0.5, range=(-20,20), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = (220,160)\n",
    "size = (101, 101)\n",
    "\n",
    "cutout_biyearly = Cutout2D(image_biyearly, position , size)\n",
    "cutout1_biyearly = cutout_biyearly.data\n",
    "\n",
    "cutout_yearly = Cutout2D(image_yearly, position , size)\n",
    "cutout1_yearly = cutout_yearly.data\n",
    "\n",
    "cutout_curr = Cutout2D(image_curr, position , size)\n",
    "cutout1_curr = cutout_curr.data\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "plt.hist(image_biyearly.flatten(),alpha=0.5, range=(-20,20), bins=200)\n",
    "plt.hist(image_curr.flatten(),alpha=0.5, range=(-20,20), bins=200)\n",
    "plt.hist(image_yearly.flatten(),alpha=0.5, range=(-20,20), bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f81a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bccc826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-diving",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-fitting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
