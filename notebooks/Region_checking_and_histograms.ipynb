{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebfe81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from astropy.nddata import Cutout2D\n",
    "from bokeh.io import output_file, output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, Range1d\n",
    "from bokeh.layouts import row, column, gridplot\n",
    "from bokeh.models.widgets import Tabs, Panel\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Determine where the visualization will be rendered\n",
    "output_notebook()\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd9868",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define all Paths here: \n",
    "#biyearly_image = '/Users/cmartlin/Desktop/postflash_2022_work/2018-2019_test_01_26_2022_idle02ayq_flc.fits'\n",
    "#current_image = '/Users/cmartlin/Desktop/postflash_2022_work/idle02ayq/idle02ayq_flc.fits'\n",
    "#yearly_image = '/Users/cmartlin/Desktop/postflash_2022_work/2018_yearly_low_10_18_2022_idn011e6s_flc.fits'\n",
    "\n",
    "#updated_yearly = glob.glob('/Users/cmartlin/Desktop/postflash_2022_work/*10_18*')\n",
    "#science_pipeline = glob.glob('/Users/cmartlin/Desktop/postflash_2022_work/i*/i*flc.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define all Paths here: \n",
    "biyearly_image = '../../postflash_2022_work/2022_ISR_testing_data/2018-2019_test_01_26_2022_idle02ayq_flc.fits'\n",
    "current_image = '../../postflash_2022_work/2022_ISR_testing_data/idle02ayq_flc.fits'\n",
    "#yearly_image = '../../postflash_2022_work/2022_ISR_testing_data/2018_yearly_low_10_18_2022_idn011e6s_flc.fits'\n",
    "yearly_image = '../../postflash_2022_work/2022_ISR_testing_data/2019_yearly_low_10_18_2022_idle02ayq_flc.fits'\n",
    "\n",
    "updated_yearly = glob.glob('../../postflash_2022_work/2022_ISR_testing_data/*10_18*')\n",
    "science_pipeline = glob.glob('../../postflash_2022_work/2022_ISR_testing_data/i*flc.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the testing data rootnames used in function:\n",
    "for f in updated_yearly: \n",
    "    print(f[-18:-9])\n",
    "    \n",
    "#Checking for year length - if this needs to change, update in function below: \n",
    "for f in updated_yearly: \n",
    "    #print(f[22:26])\n",
    "    print(f[48:52])\n",
    "    fname_left = 48\n",
    "    fname_right = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the science data rootnames used in function:\n",
    "for f in science_pipeline: \n",
    "    print(f[-18:-9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324025ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_databases(input_data, positions_list, fname_left, fname_right):\n",
    "    size = (101, 101)\n",
    "    \n",
    "    min_pos = []\n",
    "    max_pos = []\n",
    "    mean_pos = []\n",
    "    median_pos = []\n",
    "    std_pos = []\n",
    "    \n",
    "    for f in input_data: \n",
    "        image_data = fits.getdata(f,1)\n",
    "        means = []\n",
    "        maxes = []\n",
    "        mins = []\n",
    "        medians = []\n",
    "        stdevs = []\n",
    "        for p in positions_list: \n",
    "            cutout = Cutout2D(image_data, p, size)\n",
    "            cutout1 = cutout.data\n",
    "            mins.append(np.min(cutout1))\n",
    "            maxes.append(np.max(cutout1))\n",
    "            means.append(np.mean(cutout1))\n",
    "            medians.append(np.median(cutout1))\n",
    "            stdevs.append(np.std(cutout1))\n",
    "        std_pos.append(stdevs)\n",
    "        min_pos.append(mins)\n",
    "        max_pos.append(maxes)\n",
    "        mean_pos.append(means)\n",
    "        median_pos.append(medians)\n",
    "    filenames = []\n",
    "    years = []\n",
    "\n",
    "    for f in input_data:\n",
    "        filenames.append(f[-18:-9])\n",
    "        #years.append(f[22:26])\n",
    "        years.append(f[fname_left:fname_right])\n",
    "\n",
    "    positions = [220, 900, 2100, 3500, 3600]\n",
    "    positions_pipeline = ['pipe_220', 'pipe_900', 'pipe_2100', 'pipe_3500', \n",
    "                          'pipe_3600']\n",
    "       \n",
    "    # Condition to check if there is a year in the filename:\n",
    "    if (years[0].isnumeric()) == True: \n",
    "        stdev_df = pd.DataFrame(std_pos, columns=positions, dtype = float, \n",
    "                                index=filenames)\n",
    "        min_df = pd.DataFrame(min_pos, columns=positions, dtype = float, \n",
    "                                    index=filenames)\n",
    "        max_df = pd.DataFrame(max_pos, columns=positions, dtype = float, \n",
    "                                    index=filenames)\n",
    "        mean_df = pd.DataFrame(mean_pos, columns=positions, dtype = float, \n",
    "                                    index=filenames)\n",
    "        median_df = pd.DataFrame(median_pos, columns=positions, dtype = float, \n",
    "                                    index=filenames)\n",
    "        years = pd.DataFrame(years, columns=['Year'],index=filenames)\n",
    "        stdev_df = pd.concat([stdev_df, years],1)\n",
    "        min_df = pd.concat([min_df, years],1)\n",
    "        max_df = pd.concat([max_df, years],1)\n",
    "        mean_df = pd.concat([mean_df, years],1)\n",
    "        median_df = pd.concat([median_df, years],1)\n",
    "    else:\n",
    "        stdev_df = pd.DataFrame(std_pos, columns=positions_pipeline, \n",
    "                                dtype = float, index=filenames)\n",
    "        min_df = pd.DataFrame(min_pos, columns=positions_pipeline, \n",
    "                              dtype = float, index=filenames)\n",
    "        max_df = pd.DataFrame(max_pos, columns=positions_pipeline, \n",
    "                              dtype = float, index=filenames)\n",
    "        mean_df = pd.DataFrame(mean_pos, columns=positions_pipeline, \n",
    "                               dtype = float, index=filenames)\n",
    "        median_df = pd.DataFrame(median_pos, columns=positions_pipeline, \n",
    "                                 dtype = float, index=filenames)\n",
    "    \n",
    "    #return stdev_df, min_df, max_df, mean_df, median_df\n",
    "    return stdev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a07b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_list = [(220, 160), (900,700), (2100,1100), (3500,300), (3600,1700)]\n",
    "\n",
    "stdev_yearly = create_databases(updated_yearly, positions_list, fname_left, fname_right)\n",
    "stdev_pipeline = create_databases(science_pipeline, positions_list, fname_left, fname_right)\n",
    "\n",
    "combine_by_file = pd.concat([stdev_yearly,stdev_pipeline],1)\n",
    "stdev_yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_by_file['220_norm'] = (combine_by_file[220] - combine_by_file['pipe_220']) / combine_by_file['pipe_220']\n",
    "combine_by_file['900_norm'] = (combine_by_file[900] - combine_by_file['pipe_900']) / combine_by_file['pipe_900']\n",
    "combine_by_file['2100_norm'] = (combine_by_file[2100] - combine_by_file['pipe_2100']) / combine_by_file['pipe_2100']\n",
    "combine_by_file['3500_norm'] = (combine_by_file[3500] - combine_by_file['pipe_3500']) / combine_by_file['pipe_3500']\n",
    "combine_by_file['3600_norm'] = (combine_by_file[3600] - combine_by_file['pipe_3600']) / combine_by_file['pipe_3600']\n",
    "\n",
    "stdev_sorted_by_year = combine_by_file.sort_values(by=['Year'])\n",
    "stdev_sorted_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list([2012,2013,2014,2015,2016,2017,2018,2019,2020,2021])\n",
    "#x2 = list([5,1,4,6,3,2])\n",
    "x3 = list([1, 2, 3, 4, 5, 6])\n",
    "y = list(stdev_sorted_by_year['220_norm'].values)\n",
    "y2 = list(stdev_sorted_by_year['900_norm'].values)\n",
    "y3 = list(stdev_sorted_by_year['2100_norm'].values)\n",
    "y4 = list(stdev_sorted_by_year['3500_norm'].values)\n",
    "y5 = list(stdev_sorted_by_year['3600_norm'].values)\n",
    "\n",
    "y12 = np.add(y,y2)\n",
    "y34 = np.add(y3,y4)\n",
    "y125 = np.add(y12,y5)\n",
    "y12534 = np.add(y125,y34)\n",
    "y_all = y12534/5\n",
    "\n",
    "#mean of the 5 y over time, and standard dev upper limit and lower limit\n",
    "#Increase in the standard dev over time \n",
    "figure(figsize=(12, 10))\n",
    "plt.plot(x,y_all, label='Mean of all regions', linewidth=7.0, linestyle='dashed')\n",
    "plt.plot(x,y, label='Region 1')\n",
    "plt.plot(x,y2, label='Region 2')\n",
    "plt.plot(x,y3, label='Region 3')\n",
    "plt.plot(x,y4, label='Region 4')\n",
    "plt.plot(x,y5, label='Region 5')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Difference in Standard Deviation: Normalized stdev(pipeline) - stdev(yearly)')\n",
    "plt.title('Changes in Standard Deviation Differences Over Time')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('changes_in_std_normalized_overtime.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa74341",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_biyearly = fits.getdata(biyearly_image,1)\n",
    "image_curr = fits.getdata(current_image,1)\n",
    "image_yearly = fits.getdata(yearly_image,1)\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "plt.hist(image_biyearly.flatten(),alpha=0.5, range=(-20,20), bins=100, label='Bi-yearly Reference File',color='red')\n",
    "plt.hist(image_curr.flatten(),alpha=0.5, range=(-20,20), bins=100, label='Current Reference File')\n",
    "#plt.hist(image_yearly.flatten(),alpha=0.5, range=(-20,20), bins=100, label='Yearly Reference File')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.title('Fullframe Reference Images - Comparing Cadence')\n",
    "plt.legend()\n",
    "plt.savefig('fullframe_histogram_compare_biyearly_current_refs.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43f1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_biyearly = fits.getdata(biyearly_image,1)\n",
    "image_curr = fits.getdata(current_image,1)\n",
    "image_yearly = fits.getdata(yearly_image,1)\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "#plt.hist(image_biyearly.flatten(),alpha=0.5, range=(-20,20), bins=100, label='Bi-yearly Reference File')\n",
    "plt.hist(image_curr.flatten(),alpha=0.5, range=(-20,20), bins=100, label='Current Reference File')\n",
    "plt.hist(image_yearly.flatten(),alpha=0.5, range=(-20,20), bins=100, label='Yearly Reference File')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.title('Fullframe Reference Images - Comparing Cadence')\n",
    "plt.legend()\n",
    "plt.savefig('fullframe_histogram_compare_refs.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac26d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = (220,160)\n",
    "size = (101, 101)\n",
    "\n",
    "cutout_biyearly = Cutout2D(image_biyearly, position , size)\n",
    "cutout1_biyearly = cutout_biyearly.data\n",
    "\n",
    "cutout_yearly = Cutout2D(image_yearly, position , size)\n",
    "cutout1_yearly = cutout_yearly.data\n",
    "\n",
    "cutout_curr = Cutout2D(image_curr, position , size)\n",
    "cutout1_curr = cutout_curr.data\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "#plt.hist(cutout1_biyearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Bi-yearly Reference File')\n",
    "plt.hist(cutout1_curr.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Current Reference File')\n",
    "plt.hist(cutout1_yearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Yearly Reference File')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.title('Region 1 of Reference Images - Comparing Cadence')\n",
    "plt.legend()\n",
    "plt.savefig('region1_histogram_compare_refs.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d783472",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "position = (900,700)\n",
    "size = (101, 101)\n",
    "\n",
    "cutout_biyearly = Cutout2D(image_biyearly, position , size)\n",
    "cutout1_biyearly = cutout_biyearly.data\n",
    "\n",
    "cutout_yearly = Cutout2D(image_yearly, position , size)\n",
    "cutout1_yearly = cutout_yearly.data\n",
    "\n",
    "cutout_curr = Cutout2D(image_curr, position , size)\n",
    "cutout1_curr = cutout_curr.data\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "#plt.hist(cutout1_biyearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Bi-yearly Reference File')\n",
    "plt.hist(cutout1_curr.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Current Reference File')\n",
    "plt.hist(cutout1_yearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Yearly Reference File')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.title('Region 2 of Reference Images - Comparing Cadence')\n",
    "plt.legend()\n",
    "plt.savefig('region2_histogram_compare_refs.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5117b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "position = (2100,1100)\n",
    "size = (101, 101)\n",
    "\n",
    "cutout_biyearly = Cutout2D(image_biyearly, position , size)\n",
    "cutout1_biyearly = cutout_biyearly.data\n",
    "\n",
    "cutout_yearly = Cutout2D(image_yearly, position , size)\n",
    "cutout1_yearly = cutout_yearly.data\n",
    "\n",
    "cutout_curr = Cutout2D(image_curr, position , size)\n",
    "cutout1_curr = cutout_curr.data\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "#plt.hist(cutout1_biyearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Bi-yearly Reference File')\n",
    "plt.hist(cutout1_curr.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Current Reference File')\n",
    "plt.hist(cutout1_yearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Yearly Reference File')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.title('Region 3 of Reference Images - Comparing Cadence')\n",
    "plt.legend()\n",
    "plt.savefig('region3_histogram_compare_refs.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = (3500,300)\n",
    "size = (101, 101)\n",
    "\n",
    "cutout_biyearly = Cutout2D(image_biyearly, position , size)\n",
    "cutout1_biyearly = cutout_biyearly.data\n",
    "\n",
    "cutout_yearly = Cutout2D(image_yearly, position , size)\n",
    "cutout1_yearly = cutout_yearly.data\n",
    "\n",
    "cutout_curr = Cutout2D(image_curr, position , size)\n",
    "cutout1_curr = cutout_curr.data\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "#plt.hist(cutout1_biyearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Bi-yearly Reference File')\n",
    "plt.hist(cutout1_curr.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Current Reference File')\n",
    "plt.hist(cutout1_yearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Yearly Reference File')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.title('Region 4 of Reference Images - Comparing Cadence')\n",
    "plt.legend()\n",
    "plt.savefig('region4_histogram_compare_refs.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88634d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = (3600,1700)\n",
    "size = (101, 101)\n",
    "\n",
    "cutout_biyearly = Cutout2D(image_biyearly, position , size)\n",
    "cutout1_biyearly = cutout_biyearly.data\n",
    "\n",
    "cutout_yearly = Cutout2D(image_yearly, position , size)\n",
    "cutout1_yearly = cutout_yearly.data\n",
    "\n",
    "cutout_curr = Cutout2D(image_curr, position , size)\n",
    "cutout1_curr = cutout_curr.data\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "#plt.hist(cutout1_biyearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Bi-yearly Reference File')\n",
    "plt.hist(cutout1_curr.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Current Reference File')\n",
    "plt.hist(cutout1_yearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Yearly Reference File')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.title('Region 5 of Reference Images - Comparing Cadence')\n",
    "plt.legend()\n",
    "plt.savefig('region5_histogram_compare_refs.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e1673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_databases(input_data, positions_list, fname_left, fname_right):\n",
    "    size = (101, 101)\n",
    "    \n",
    "    min_pos = []\n",
    "    max_pos = []\n",
    "    mean_pos = []\n",
    "    median_pos = []\n",
    "    std_pos = []\n",
    "    \n",
    "    for f in input_data: \n",
    "        image_data = fits.getdata(f,1)\n",
    "        means = []\n",
    "        maxes = []\n",
    "        mins = []\n",
    "        medians = []\n",
    "        stdevs = []\n",
    "        for p in positions_list: \n",
    "            cutout = Cutout2D(image_data, p, size)\n",
    "            cutout1 = cutout.data\n",
    "            mins.append(np.min(cutout1))\n",
    "            maxes.append(np.max(cutout1))\n",
    "            means.append(np.mean(cutout1))\n",
    "            medians.append(np.median(cutout1))\n",
    "            stdevs.append(np.std(cutout1))\n",
    "        std_pos.append(stdevs)\n",
    "        min_pos.append(mins)\n",
    "        max_pos.append(maxes)\n",
    "        mean_pos.append(means)\n",
    "        median_pos.append(medians)\n",
    "    filenames = []\n",
    "    years = []\n",
    "\n",
    "    for f in input_data:\n",
    "        filenames.append(f[-18:-9])\n",
    "        years.append(f[fname_left:fname_right])\n",
    "\n",
    "    positions = ['stdev_220', 'stdev_900', 'stdev_2100', 'stdev_3500', \n",
    "                 'stdev_3600']\n",
    "    positions_min = ['min_220', 'min_900', 'min_2100', 'min_3500', \n",
    "                          'min_3600']\n",
    "    positions_max = ['max_220', 'max_900', 'max_2100', 'max_3500', \n",
    "                          'max_3600']\n",
    "    positions_mean = ['mean_220', 'mean_900', 'mean_2100', 'mean_3500', \n",
    "                          'mean_3600']\n",
    "    positions_med = ['med_220', 'med_900', 'med_2100', 'med_3500', \n",
    "                          'med_3600']\n",
    "    positions_pipeline = ['pipe_220', 'pipe_900', 'pipe_2100', 'pipe_3500', \n",
    "                          'pipe_3600']\n",
    "    pos_minpipe = ['min_pipe_220', 'min_pipe_900', 'min_pipe_2100', \n",
    "                   'min_pipe_3500', 'min_pipe_3600']\n",
    "    pos_maxpipe = ['max_pipe_220', 'max_pipe_900', 'max_pipe_2100', \n",
    "                   'max_pipe_3500', 'max_pipe_3600']\n",
    "    pos_meanpipe = ['mean_pipe_220', 'mean_pipe_900', 'mean_pipe_2100', \n",
    "                    'mean_pipe_3500', 'mean_pipe_3600']\n",
    "    pos_medpipe = ['mean_pipe_220', 'mean_pipe_900', 'mean_pipe_2100', \n",
    "                   'mean_pipe_3500', 'mean_pipe_3600']\n",
    "       \n",
    "    # Condition to check if there is a year in the filename:\n",
    "    if (years[0].isnumeric()) == True: \n",
    "        stdev_df = pd.DataFrame(std_pos, columns=positions, dtype = float, \n",
    "                                index=filenames)\n",
    "        min_df = pd.DataFrame(min_pos, columns=positions_min, dtype = float, \n",
    "                                    index=filenames)\n",
    "        max_df = pd.DataFrame(max_pos, columns=positions_max, dtype = float, \n",
    "                                    index=filenames)\n",
    "        mean_df = pd.DataFrame(mean_pos, columns=positions_mean, dtype = float, \n",
    "                                    index=filenames)\n",
    "        median_df = pd.DataFrame(median_pos, columns=positions_med, dtype = float, \n",
    "                                    index=filenames)\n",
    "        years = pd.DataFrame(years,columns=['Year'], index=filenames)\n",
    "        stdev_df = pd.concat([stdev_df, years],1)\n",
    "        min_df = pd.concat([min_df, years],1)\n",
    "        max_df = pd.concat([max_df, years],1)\n",
    "        mean_df = pd.concat([mean_df, years],1)\n",
    "        median_df = pd.concat([median_df, years],1)\n",
    "    else:\n",
    "        stdev_df = pd.DataFrame(std_pos, columns=positions_pipeline, \n",
    "                                dtype = float, index=filenames)\n",
    "        min_df = pd.DataFrame(min_pos, columns=pos_minpipe, \n",
    "                              dtype = float, index=filenames)\n",
    "        max_df = pd.DataFrame(max_pos, columns=pos_maxpipe, \n",
    "                              dtype = float, index=filenames)\n",
    "        mean_df = pd.DataFrame(mean_pos, columns=pos_meanpipe, \n",
    "                               dtype = float, index=filenames)\n",
    "        median_df = pd.DataFrame(median_pos, columns=pos_medpipe, \n",
    "                                 dtype = float, index=filenames)\n",
    "    \n",
    "    return stdev_df, min_df, max_df, mean_df, median_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945938b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_list = [(220, 160), (900,700), (2100,1100), (3500,300), (3600,1700)]\n",
    "\n",
    "stdev_yearly, min_yearly, max_yearly, mean_yearly, median_yearly = create_databases(updated_yearly, positions_list, fname_left, fname_right)\n",
    "yearly_stats = pd.concat([stdev_yearly,min_yearly, max_yearly, mean_yearly, median_yearly],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5dc6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_stats = yearly_stats.T.drop_duplicates().T\n",
    "yearly_stats = yearly_stats.sort_values(by=['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d92363",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_stats_table = yearly_stats.T\n",
    "yearly_stats_table.index\n",
    "ordered_yearly_stats = yearly_stats_table.reindex(['Year', \n",
    "                                                  'stdev_220', 'stdev_900', 'stdev_2100', 'stdev_3500', 'stdev_3600',\n",
    "                                                  'min_220', 'min_900', 'min_2100', 'min_3500', 'min_3600',\n",
    "                                                  'max_220', 'max_900', 'max_2100', 'max_3500', 'max_3600', \n",
    "                                                  'mean_220','mean_900', 'mean_2100', 'mean_3500', 'mean_3600',\n",
    "                                                  'med_220', 'med_900','med_2100', 'med_3500', 'med_3600'])\n",
    "ordered_yearly_stats.rename(index={'stdev_220': 'stdev Region 1','stdev_900': 'Region 2', 'stdev_2100': 'Region 3',\n",
    "                                  'stdev_3500': 'Region 4','stdev_3600': 'Region 5', 'min_220': 'min Region 1',\n",
    "                                   'min_900': 'Region 2', 'min_2100': 'Region 3',\n",
    "                                  'min_3500': 'Region 4','min_3600': 'Region 5','max_220': 'max Region 1',\n",
    "                                   'max_900': 'Region 2', 'max_2100': 'Region 3',\n",
    "                                  'max_3500': 'Region 4','max_3600': 'Region 5','mean_220': 'mean Region 1',\n",
    "                                   'mean_900': 'Region 2', 'mean_2100': 'Region 3',\n",
    "                                  'mean_3500': 'Region 4','mean_3600': 'Region 5',\n",
    "                                   'med_220': 'med Region 1','med_900': 'Region 2', 'med_2100': 'Region 3',\n",
    "                                  'med_3500': 'Region 4','med_3600': 'Region 5'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5444df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_yearly_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca7095",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = (3500,300)\n",
    "size = (101, 101)\n",
    "\n",
    "cutout_biyearly = Cutout2D(image_biyearly, position , size)\n",
    "cutout1_biyearly = cutout_biyearly.data\n",
    "\n",
    "cutout_yearly = Cutout2D(image_yearly, position , size)\n",
    "cutout1_yearly = cutout_yearly.data\n",
    "\n",
    "cutout_curr = Cutout2D(image_curr, position , size)\n",
    "cutout1_curr = cutout_curr.data\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "plt.hist(cutout1_biyearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Bi-yearly Reference File')\n",
    "plt.hist(cutout1_curr.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Current Reference File')\n",
    "#plt.hist(cutout1_yearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Yearly Reference File')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.title('Region 4 of Reference Images - Comparing Cadence')\n",
    "plt.legend()\n",
    "plt.savefig('region4_histogram_compare_refs.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = (3600,1700)\n",
    "size = (101, 101)\n",
    "\n",
    "cutout_biyearly = Cutout2D(image_biyearly, position , size)\n",
    "cutout1_biyearly = cutout_biyearly.data\n",
    "\n",
    "cutout_yearly = Cutout2D(image_yearly, position , size)\n",
    "cutout1_yearly = cutout_yearly.data\n",
    "\n",
    "cutout_curr = Cutout2D(image_curr, position , size)\n",
    "cutout1_curr = cutout_curr.data\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "plt.hist(cutout1_biyearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Bi-yearly Reference File')\n",
    "plt.hist(cutout1_curr.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Current Reference File')\n",
    "#plt.hist(cutout1_yearly.flatten(),alpha=0.5, range=(-20,20), bins=200, label='Yearly Reference File')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.title('Region 5 of Reference Images - Comparing Cadence')\n",
    "plt.legend()\n",
    "plt.savefig('region5_histogram_compare_refs.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_databases(input_data, positions_list, fname_left, fname_right):\n",
    "    size = (101, 101)\n",
    "    \n",
    "    min_pos = []\n",
    "    max_pos = []\n",
    "    mean_pos = []\n",
    "    median_pos = []\n",
    "    std_pos = []\n",
    "    \n",
    "    for f in input_data: \n",
    "        image_data = fits.getdata(f,1)\n",
    "        means = []\n",
    "        maxes = []\n",
    "        mins = []\n",
    "        medians = []\n",
    "        stdevs = []\n",
    "        for p in positions_list: \n",
    "            cutout = Cutout2D(image_data, p, size)\n",
    "            cutout1 = cutout.data\n",
    "            mins.append(np.min(cutout1))\n",
    "            maxes.append(np.max(cutout1))\n",
    "            means.append(np.mean(cutout1))\n",
    "            medians.append(np.median(cutout1))\n",
    "            stdevs.append(np.std(cutout1))\n",
    "        std_pos.append(stdevs)\n",
    "        min_pos.append(mins)\n",
    "        max_pos.append(maxes)\n",
    "        mean_pos.append(means)\n",
    "        median_pos.append(medians)\n",
    "    filenames = []\n",
    "    years = []\n",
    "\n",
    "    for f in input_data:\n",
    "        filenames.append(f[-18:-9])\n",
    "        years.append(f[fname_left:fname_right])\n",
    "\n",
    "    positions = ['stdev_220', 'stdev_900', 'stdev_2100', 'stdev_3500', \n",
    "                 'stdev_3600']\n",
    "    positions_min = ['min_220', 'min_900', 'min_2100', 'min_3500', \n",
    "                          'min_3600']\n",
    "    positions_max = ['max_220', 'max_900', 'max_2100', 'max_3500', \n",
    "                          'max_3600']\n",
    "    positions_mean = ['mean_220', 'mean_900', 'mean_2100', 'mean_3500', \n",
    "                          'mean_3600']\n",
    "    positions_med = ['med_220', 'med_900', 'med_2100', 'med_3500', \n",
    "                          'med_3600']\n",
    "    positions_pipeline = ['pipe_220', 'pipe_900', 'pipe_2100', 'pipe_3500', \n",
    "                          'pipe_3600']\n",
    "    pos_minpipe = ['min_pipe_220', 'min_pipe_900', 'min_pipe_2100', \n",
    "                   'min_pipe_3500', 'min_pipe_3600']\n",
    "    pos_maxpipe = ['max_pipe_220', 'max_pipe_900', 'max_pipe_2100', \n",
    "                   'max_pipe_3500', 'max_pipe_3600']\n",
    "    pos_meanpipe = ['mean_pipe_220', 'mean_pipe_900', 'mean_pipe_2100', \n",
    "                    'mean_pipe_3500', 'mean_pipe_3600']\n",
    "    pos_medpipe = ['mean_pipe_220', 'mean_pipe_900', 'mean_pipe_2100', \n",
    "                   'mean_pipe_3500', 'mean_pipe_3600']\n",
    "       \n",
    "    # Condition to check if there is a year in the filename:\n",
    "    if (years[0].isnumeric()) == True: \n",
    "        stdev_df = pd.DataFrame(std_pos, columns=positions, dtype = float, \n",
    "                                index=filenames)\n",
    "        min_df = pd.DataFrame(min_pos, columns=positions_min, dtype = float, \n",
    "                                    index=filenames)\n",
    "        max_df = pd.DataFrame(max_pos, columns=positions_max, dtype = float, \n",
    "                                    index=filenames)\n",
    "        mean_df = pd.DataFrame(mean_pos, columns=positions_mean, dtype = float, \n",
    "                                    index=filenames)\n",
    "        median_df = pd.DataFrame(median_pos, columns=positions_med, dtype = float, \n",
    "                                    index=filenames)\n",
    "        years = pd.DataFrame(years,columns=['Year'], index=filenames)\n",
    "        stdev_df = pd.concat([stdev_df, years],1)\n",
    "        min_df = pd.concat([min_df, years],1)\n",
    "        max_df = pd.concat([max_df, years],1)\n",
    "        mean_df = pd.concat([mean_df, years],1)\n",
    "        median_df = pd.concat([median_df, years],1)\n",
    "    else:\n",
    "        stdev_df = pd.DataFrame(std_pos, columns=positions_pipeline, \n",
    "                                dtype = float, index=filenames)\n",
    "        min_df = pd.DataFrame(min_pos, columns=pos_minpipe, \n",
    "                              dtype = float, index=filenames)\n",
    "        max_df = pd.DataFrame(max_pos, columns=pos_maxpipe, \n",
    "                              dtype = float, index=filenames)\n",
    "        mean_df = pd.DataFrame(mean_pos, columns=pos_meanpipe, \n",
    "                               dtype = float, index=filenames)\n",
    "        median_df = pd.DataFrame(median_pos, columns=pos_medpipe, \n",
    "                                 dtype = float, index=filenames)\n",
    "    \n",
    "    return stdev_df, min_df, max_df, mean_df, median_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d4a0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_list = [(220, 160), (900,700), (2100,1100), (3500,300), (3600,1700)]\n",
    "\n",
    "stdev_yearly, min_yearly, max_yearly, mean_yearly, median_yearly = create_databases(updated_yearly, positions_list, fname_left, fname_right)\n",
    "yearly_stats = pd.concat([stdev_yearly,min_yearly, max_yearly, mean_yearly, median_yearly],1)\n",
    "bi_yearly_stats = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeaead8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3717302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c549e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf6999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
