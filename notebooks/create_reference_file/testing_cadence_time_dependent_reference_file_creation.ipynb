{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7d1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1652e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = '/Users/cmartlin/Desktop/'\n",
    "today = '12-09-2022'\n",
    "postflash_data = pd.read_pickle('../../2022_data/Feb_2022_flc_all_stats_postflash.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(list_of_files,out_file,error_file):\n",
    "    hdr = fits.getheader(list_of_files[0], 1)\n",
    "    nx = hdr['NAXIS1']\n",
    "    ny = hdr['NAXIS2']\n",
    "    nf = len(list_of_files)\n",
    "    data_array_1 = np.empty((nf, ny, nx), dtype=float)\n",
    "    data_array_2 = np.empty((nf, ny, nx), dtype=float)\n",
    "    set_data=fits.getdata(list_of_files[0], 1)\n",
    "    rms_1 = np.zeros(len(list_of_files), dtype=float)\n",
    "    rms_2 = np.zeros(len(list_of_files), dtype=float)\n",
    "    error_array_1 = np.empty((nf, ny, nx), dtype=float)\n",
    "    error_array_2 = np.empty((nf, ny, nx), dtype=float)\n",
    "    total_error_1 = np.zeros_like(set_data, dtype=float)\n",
    "    total_error_2 = np.zeros_like(set_data, dtype=float)\n",
    "    for i , f in enumerate(list_of_files):\n",
    "        data_1=fits.getdata(f, 1)\n",
    "        data_2=fits.getdata(f, 4)\n",
    "        error_1=fits.getdata(f, 2)\n",
    "        error_2=fits.getdata(f, 5)\n",
    "        DQ_1=fits.getdata(f, 3)\n",
    "        DQ_2=fits.getdata(f, 6)\n",
    "        #data_1=data1\n",
    "        #data_2=data2\n",
    "        mask_1=np.zeros_like(data_1, dtype=bool)\n",
    "        mask_2=np.zeros_like(data_2, dtype=bool)\n",
    "        mask_1[DQ_1>=2**13]= True\n",
    "        mask_2[DQ_2>=2**13]= True\n",
    "        error_1[(0<DQ_1 & (DQ_1<2**13))]=0.00001\n",
    "        error_2[(0<DQ_2& (DQ_2<2**13))]=0.00001\n",
    "        error_1_sq=error_1**2\n",
    "        error_2_sq=error_2**2\n",
    "        masked_data_1= ma.array(data=data_1, mask=mask_1)\n",
    "        masked_data_2= ma.array(data=data_2, mask=mask_2)\n",
    "        data_array_1[i, :, :] = masked_data_1\n",
    "        rms_1[i] = masked_data_1.std()\n",
    "        data_array_2[i, :, :] = masked_data_2\n",
    "        rms_2[i] = masked_data_2.std()\n",
    "        total_error_1=total_error_1+(error_1_sq)\n",
    "        total_error_2=total_error_2+(error_2_sq)\n",
    "    sr_total_error_1=np.sqrt(total_error_1)\n",
    "    sr_total_error_2=np.sqrt(total_error_2)\n",
    "    fin_error_1=(sr_total_error_1/(float(len(list_of_files))))\n",
    "    fin_error_2=(sr_total_error_2/(float(len(list_of_files))))\n",
    "    image_median_1 = np.median(data_array_1, axis=0)\n",
    "    image_median_2 = np.median(data_array_2, axis=0)\n",
    "    new_hdul = fits.HDUList()\n",
    "    new_hdul.append(fits.ImageHDU(image_median_1))\n",
    "    new_hdul.append(fits.ImageHDU(image_median_2))\n",
    "    new_hdul.writeto(out_file, overwrite=True)\n",
    "    #error\n",
    "    new_hdul = fits.HDUList()\n",
    "    new_hdul.append(fits.ImageHDU(fin_error_1))\n",
    "    new_hdul.append(fits.ImageHDU(fin_error_2))\n",
    "    new_hdul.writeto(error_file,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reference_file(year, working_directory, today, cadence):\n",
    "    fullframe_pf = postflash_data.loc[(postflash_data['subarray'] == False)] \n",
    "    shutters = ('A', 'B')\n",
    "    for shutter in shutters: \n",
    "        fullframe_pf = postflash_data.loc[(postflash_data['subarray'] == False) & (postflash_data['shutter'] == '{}'.format(shutter)) & (postflash_data['flash_cur'] == 'MED') & (postflash_data['flash_dur'] == 100.0)] \n",
    "        fullframe_pf_year = fullframe_pf[(fullframe_pf['datetime'] > '{}-01-01 00:00:00'.format(str(year))) & (fullframe_pf['datetime'] < '{}-01-01 00:00:00'.format(str(year+cadence)))]\n",
    "        paths_year = fullframe_pf_year.path.tolist()\n",
    "        print(len(paths_year))\n",
    "        outfile_year = '{}{}_cadence{}_fullframe_{}_flc_stack_{}.fits'.format(working_directory,str(year), str(cadence), shutter, today)\n",
    "        error_outfile_year = '{}{}_cadence{}_fullframe_{}_flc_error_stack_{}.fits'.format(working_directory,str(year), str(cadence), shutter, today)\n",
    "        print(outfile_year)\n",
    "\n",
    "    return paths_year, outfile_year, error_outfile_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6feff6",
   "metadata": {},
   "source": [
    "To run the stacking code you need to run: stack(path_list, path_outfile, path_error_outfile)\n",
    "\n",
    "path_list - this is the list you create from the path column of the subset of the pandas database. \n",
    "\n",
    "path_outfile - this is the path and filename you want for your outfile. If you just put \"outfile.fits\" the file will save where you are running the notebook. I suggest start with the path to wfc3u so we keep them in a central location and to have the file be descriptive. Ex: \"/grp/hst/wfc3u/postflash_2021/2020_stack_flt.fits\"\n",
    "\n",
    "path_error_outfile - this is the path and filename you want for your outfile of the calcuated error. If you just put \"outfile.fits\" the file will save where you are running the notebook. I suggest start with the path to wfc3u so we keep them in a central location and to have the file be descriptive. Ex: \"/grp/hst/wfc3u/postflash_2021/2020_stack_error_flt.fits\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567f256",
   "metadata": {},
   "source": [
    "Below I show how to create the proper cut for a single year of data from the pandas database which has already been cut to Fullframe, Medium current, Shutter A. \n",
    "\n",
    "From there I update the path_list, outfile, and error_outfile to be specfic to the year being tested. \n",
    "\n",
    "Once that is run, I use those parameters to run the `stack` function. Outputs will be saved to '/grp/hst/wfc3u/postflash_2021/'. \n",
    "\n",
    "I then update a copy of a new set to 2013 and run `stack` on that set. \n",
    "\n",
    "The following years/groups of years can be done the same way. Following the creation of all the stacked files we will still need to calculate the mean/median of the stacked images to plot them over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081de8ba",
   "metadata": {},
   "source": [
    "bi-yearly creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2012, 2014, 2016, 2018, 2020]\n",
    "cadence = 2\n",
    "\n",
    "for y in years: \n",
    "    paths_year, outfile_year, error_outfile_year = create_reference_file(y, working_directory, today, cadence)\n",
    "    #stack(paths_year, outfile_year, error_outfile_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3c84d",
   "metadata": {},
   "source": [
    "5 year grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2012,2017]\n",
    "cadence = 5\n",
    "\n",
    "for y in years: \n",
    "    paths_year, outfile_year, error_outfile_year = create_reference_file(y, working_directory, today, cadence)\n",
    "    #stack(paths_year, outfile_year, error_outfile_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-floor",
   "metadata": {},
   "source": [
    "All years grouping: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f261b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2012]\n",
    "cadence = 10\n",
    "\n",
    "for y in years: \n",
    "    paths_year, outfile_year, error_outfile_year = create_reference_file(y, working_directory, today, cadence)\n",
    "    #stack(paths_year, outfile_year, error_outfile_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b71b22",
   "metadata": {},
   "source": [
    "Adding a change_permissions function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_permissions(path_to_files):\n",
    "    \"\"\"Change permissions of the output files and directories. \n",
    "        Code structure borrowed from cal_uvis_make_darks/FileIO.py. \n",
    "        Parameters\n",
    "        ----------\n",
    "            path_to_files : str\n",
    "                Path to the directory that contains the files you want\n",
    "                to update. \n",
    "    \"\"\"\n",
    "    \n",
    "    os.chdir(path_to_files)\n",
    "    all_directories = glob.glob('*')\n",
    "\n",
    "    for directory in all_directories:\n",
    "        try:\n",
    "            os.chmod(directory, 0o775)\n",
    "        except: \n",
    "            print('Could not change permissions.')\n",
    "        for root, subdirs, files in os.walk(directory):\n",
    "            for subdir in subdirs:\n",
    "                try:\n",
    "                    os.chmod(os.path.join(root, subdir), 0o775)\n",
    "                except: \n",
    "                    print('Could not change permissions.')\n",
    "            for name in files:\n",
    "                try:\n",
    "                    os.chmod(os.path.join(root, name), 0o775)\n",
    "                except: \n",
    "                    print('Could not change permissions.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1300ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_permissions(working_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
