{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "postflash_data = pd.read_pickle('/grp/hst/wfc3u/postflash_2021/flc_all_stats_postflash.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullframe_pf = postflash_data.loc[(postflash_data['subarray'] == False)] \n",
    "fullframe_pf_A = postflash_data.loc[(postflash_data['subarray'] == False) & (postflash_data['shutter'] == 'A') & (postflash_data['flash_cur'] == 'MED') & (postflash_data['flash_dur'] == 100.0)] \n",
    "fullframe_pf_B = postflash_data.loc[(postflash_data['subarray'] == False) & (postflash_data['shutter'] == 'B') & (postflash_data['flash_cur'] == 'MED') & (postflash_data['flash_dur'] == 100.0)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(list_of_files,out_file,error_file):\n",
    "    hdr = fits.getheader(list_of_files[0], 1)\n",
    "    nx = hdr['NAXIS1']\n",
    "    ny = hdr['NAXIS2']\n",
    "    nf = len(list_of_files)\n",
    "    # Setting up the empty data, rms, and error arrays and getting the data\n",
    "    data_array_1 = np.empty((nf, ny, nx), dtype=float)\n",
    "    data_array_2 = np.empty((nf, ny, nx), dtype=float)\n",
    "    set_data=fits.getdata(list_of_files[0], 1)\n",
    "    rms_1 = np.zeros(len(list_of_files), dtype=float)\n",
    "    rms_2 = np.zeros(len(list_of_files), dtype=float)\n",
    "    error_array_1 = np.empty((nf, ny, nx), dtype=float)\n",
    "    error_array_2 = np.empty((nf, ny, nx), dtype=float)\n",
    "    total_error_1 = np.zeros_like(set_data, dtype=float)\n",
    "    total_error_2 = np.zeros_like(set_data, dtype=float)\n",
    "    for i , f in enumerate(list_of_files):\n",
    "        data_1=fits.getdata(f, 1)\n",
    "        data_2=fits.getdata(f, 4)\n",
    "        error_1=fits.getdata(f, 2)\n",
    "        error_2=fits.getdata(f, 5)\n",
    "        DQ_1=fits.getdata(f, 3)\n",
    "        DQ_2=fits.getdata(f, 6)\n",
    "        #data_1=data1\n",
    "        #data_2=data2\n",
    "        mask_1=np.zeros_like(data_1, dtype=bool)\n",
    "        mask_2=np.zeros_like(data_2, dtype=bool)\n",
    "        mask_1[DQ_1>=2**13]= True\n",
    "        mask_2[DQ_2>=2**13]= True\n",
    "        error_1[(0<DQ_1 & (DQ_1<2**13))]=0.00001\n",
    "        error_2[(0<DQ_2& (DQ_2<2**13))]=0.00001\n",
    "        error_1_sq=error_1**2\n",
    "        error_2_sq=error_2**2\n",
    "        masked_data_1= ma.array(data=data_1, mask=mask_1)\n",
    "        masked_data_2= ma.array(data=data_2, mask=mask_2)\n",
    "        data_array_1[i, :, :] = masked_data_1\n",
    "        rms_1[i] = masked_data_1.std()\n",
    "        data_array_2[i, :, :] = masked_data_2\n",
    "        rms_2[i] = masked_data_2.std()\n",
    "        total_error_1=total_error_1+(error_1_sq)\n",
    "        total_error_2=total_error_2+(error_2_sq)\n",
    "    sr_total_error_1=np.sqrt(total_error_1)\n",
    "    sr_total_error_2=np.sqrt(total_error_2)\n",
    "    fin_error_1=(sr_total_error_1/(float(len(list_of_files))))\n",
    "    fin_error_2=(sr_total_error_2/(float(len(list_of_files))))\n",
    "    image_median_1 = np.median(data_array_1, axis=0)\n",
    "    image_median_2 = np.median(data_array_2, axis=0)\n",
    "    new_hdul = fits.HDUList()\n",
    "    new_hdul.append(fits.ImageHDU(image_median_1))\n",
    "    new_hdul.append(fits.ImageHDU(image_median_2))\n",
    "    new_hdul.writeto(out_file, overwrite=True)\n",
    "    #error\n",
    "    new_hdul = fits.HDUList()\n",
    "    new_hdul.append(fits.ImageHDU(fin_error_1))\n",
    "    new_hdul.append(fits.ImageHDU(fin_error_2))\n",
    "    new_hdul.writeto(error_file,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullframe_pf_A_2012_2016 = fullframe_pf_A[(fullframe_pf_A['datetime'] > '2012-01-01 00:00:00') & (fullframe_pf_A['datetime'] < '2017-01-01 00:00:00')]\n",
    "paths_2012_2016 = fullframe_pf_A_2012_2016.path.tolist()\n",
    "print(len(paths_2012_2016))\n",
    "outfile_2012_2016 = '/grp/hst/wfc3u/postflash_2021/2012_2016_fullframe_A_flc_stack.fits'\n",
    "error_outfile_2012_2016 = '/grp/hst/wfc3u/postflash_2021/2012_2016_fullframe_A_flc_error_stack.fits'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullframe_pf_B_2012_2016 = fullframe_pf_B[(fullframe_pf_B['datetime'] > '2012-01-01 00:00:00') & (fullframe_pf_B['datetime'] < '2017-01-01 00:00:00')]\n",
    "paths_2012_2016_B = fullframe_pf_B_2012_2016.path.tolist()\n",
    "print(len(paths_2012_2016_B))\n",
    "outfile_2012_2016_B = '/grp/hst/wfc3u/postflash_2021/2012_2016_fullframe_B_flc_stack.fits'\n",
    "error_outfile_2012_2016_B = '/grp/hst/wfc3u/postflash_2021/2012_2016_fullframe_B_flc_error_stack.fits'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack(paths_2012_2016, outfile_2012_2016, error_outfile_2012_2016)\n",
    "\n",
    "stack(paths_2012_2016_B, outfile_2012_2016_B, error_outfile_2012_2016_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_A = fullframe_pf_A.path.tolist()\n",
    "print(len(paths_A))\n",
    "outfile_all_A = '/grp/hst/wfc3u/postflash_2021/all_fullframe_A_flc_stack.fits'\n",
    "error_outfile_all_A = '/grp/hst/wfc3u/postflash_2021/all_fullframe_A_flc_error_stack.fits'\n",
    "\n",
    "paths_B = fullframe_pf_B.path.tolist()\n",
    "print(len(paths_B))\n",
    "outfile_all_B = '/grp/hst/wfc3u/postflash_2021/all_fullframe_B_flc_stack.fits'\n",
    "error_outfile_all_B = '/grp/hst/wfc3u/postflash_2021/all_fullframe_B_flc_error_stack.fits'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack(paths_A, outfile_all_A, error_outfile_all_A)\n",
    "\n",
    "stack(paths_B, outfile_all_B, error_outfile_all_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullframe_pf_A_2017_2021 = fullframe_pf_A[(fullframe_pf_A['datetime'] > '2017-01-01 00:00:00') & (fullframe_pf_A['datetime'] < '2022-01-01 00:00:00')]\n",
    "paths_2017_2021_A = fullframe_pf_A_2017_2021.path.tolist()\n",
    "print(len(paths_2017_2021_A))\n",
    "outfile_2017_2021_A = '/grp/hst/wfc3u/postflash_2021/2017_2021_fullframe_A_flc_stack.fits'\n",
    "error_outfile_2017_2021_A = '/grp/hst/wfc3u/postflash_2021/2017_2021_fullframe_A_flc_error_stack.fits'\n",
    "\n",
    "fullframe_pf_B_2017_2021 = fullframe_pf_B[(fullframe_pf_B['datetime'] > '2017-01-01 00:00:00') & (fullframe_pf_B['datetime'] < '2022-01-01 00:00:00')]\n",
    "paths_2017_2021_B = fullframe_pf_B_2017_2021.path.tolist()\n",
    "print(len(paths_2017_2021_B))\n",
    "outfile_2017_2021_B = '/grp/hst/wfc3u/postflash_2021/2017_2021_fullframe_B_flc_stack.fits'\n",
    "error_outfile_2017_2021_B = '/grp/hst/wfc3u/postflash_2021/2017_2021_fullframe_B_flc_error_stack.fits'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack(paths_2017_2021_A, outfile_2017_2021_A, error_outfile_2017_2021_A)\n",
    "\n",
    "stack(paths_2017_2021_B, outfile_2017_2021_B, error_outfile_2017_2021_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-logistics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
