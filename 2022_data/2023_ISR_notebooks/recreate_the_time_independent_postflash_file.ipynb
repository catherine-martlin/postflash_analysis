{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = '/Users/cmartlin/Desktop/'\n",
    "today = '12_09_2022'\n",
    "postflash_data = pd.read_pickle('../../2022_data/Feb_2022_flc_all_stats_postflash.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "postflash_data=postflash_data.sort_values(by='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reference_file(year, working_directory, today, cadence, postflash_data):\n",
    "    \"\"\"This function will use input information to run the stack()\n",
    "    function and create specific file names for the outputs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    year: int\n",
    "        The year as an integer input.\n",
    "    \n",
    "    working_directory: str\n",
    "        The path the files will be saved to. Needs trailing '\\'\n",
    "    \n",
    "    today: str\n",
    "        Format isn't important, needed to add date to filenames.\n",
    "    \n",
    "    cadence: int\n",
    "        Number of years you want stacked. 1 = 1 year, 2 = biyearly, etc.\n",
    "    \n",
    "    postflash_data: pandas dataframe\n",
    "        Dataframe to define the data you are using.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    paths_year: str\n",
    "        List of all FITS file needed to stack.\n",
    "    \n",
    "    outfile_year: str\n",
    "        Filename for the outfile specified by year.\n",
    "    \n",
    "    error_outfile_year: str\n",
    "        Filename for the error outfile specified by year.\n",
    "    \n",
    "    \"\"\"\n",
    "    fullframe_pf = postflash_data.loc[(postflash_data['subarray'] == False)]\n",
    "    shutters = ('A', 'B')\n",
    "    for shutter in shutters:\n",
    "        fullframe_pf = postflash_data.loc[(postflash_data['subarray'] == False) & (postflash_data['shutter'] == '{}'.format(shutter)) & (postflash_data['flash_cur'] == 'MED') & (postflash_data['flash_dur'] == 100.0)]\n",
    "        if cadence == 1:\n",
    "            if year == 2012:\n",
    "                fullframe_pf_year = fullframe_pf[(fullframe_pf['datetime'] > '{}-01-01 00:00:00'.format(str(year))) & (fullframe_pf['datetime'] < '{}-11-14 00:00:00'.format(str(year+1)))]\n",
    "            else:\n",
    "                fullframe_pf_year = fullframe_pf[(fullframe_pf['datetime'] > '{}-01-01 00:00:00'.format(str(year))) & (fullframe_pf['datetime'] < '{}-01-01 00:00:00'.format(str(year+1)))]\n",
    "            paths_year = fullframe_pf_year.path.tolist()\n",
    "            print(len(paths_year))\n",
    "            outfile_year = '{}{}_fullframe_{}_flc_stack_{}.fits'.format(working_directory,str(year), shutter, today)\n",
    "            error_outfile_year = '{}{}_fullframe_{}_flc_error_stack_{}.fits'.format(working_directory,str(year), shutter, today)\n",
    "            print(outfile_year)\n",
    "        else:\n",
    "            fullframe_pf = postflash_data.loc[(postflash_data['subarray'] == False) & (postflash_data['shutter'] == '{}'.format(shutter)) & (postflash_data['flash_cur'] == 'MED') & (postflash_data['flash_dur'] == 100.0)]\n",
    "            fullframe_pf_year = fullframe_pf[(fullframe_pf['datetime'] > '{}-01-01 00:00:00'.format(str(year))) & (fullframe_pf['datetime'] < '{}-01-01 00:00:00'.format(str(year+cadence)))]\n",
    "            paths_year = fullframe_pf_year.path.tolist()\n",
    "            print(len(paths_year))\n",
    "            outfile_year = '{}{}_cadence{}_fullframe_{}_flc_stack_{}.fits'.format(working_directory,str(year), str(cadence), shutter, today)\n",
    "            error_outfile_year = '{}{}_cadence{}_fullframe_{}_flc_error_stack_{}.fits'.format(working_directory,str(year), str(cadence), shutter, today)\n",
    "            print(outfile_year)\n",
    "\n",
    "    return paths_year, outfile_year, error_outfile_year, fullframe_pf_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "postflash_data=postflash_data.sort_values(by='datetime')\n",
    "fullframe_pf = postflash_data.loc[(postflash_data['subarray'] == False)]\n",
    "\n",
    "start_year = '2009'\n",
    "end_year = '2016'\n",
    "\n",
    "shutters = ('A', 'B')\n",
    "for shutter in shutters:\n",
    "    fullframe_pf = postflash_data.loc[(postflash_data['subarray'] == False) & (postflash_data['shutter'] == '{}'.format(shutter)) & (postflash_data['flash_cur'] == 'MED') & (postflash_data['flash_dur'] == 100.0)]\n",
    "    fullframe_pf_year = fullframe_pf[(fullframe_pf['datetime'] > '{}-01-01 00:00:00'.format(start_year)) & (fullframe_pf['datetime'] < '{}-01-01 00:00:00'.format(end_year))]\n",
    "    paths_year = fullframe_pf_year.path.tolist()\n",
    "    print(len(paths_year))\n",
    "    outfile_year = '{}testing_pipeline_{}_shutter{}.fits'.format(working_directory, today, shutter)\n",
    "    error_outfile_year = '{}testing_pipeline_error_stack_{}_shutter{}.fits'.format(working_directory, today, shutter)\n",
    "    print(outfile_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd70b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(list_of_files, outfile, error_file):\n",
    "    \"\"\"This function will stack a set of FITS images and create a masked\n",
    "    median file along with an error file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_files: str\n",
    "        This is the list you create from the path column of the\n",
    "        subset of the pandas database.\n",
    "\n",
    "    outfile: str\n",
    "        This is the path and filename you want for your outfile.\n",
    "\n",
    "    error_file: str\n",
    "    This is the path and filename you want for your\n",
    "        outfile of the calcuated error.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Gets the file size\n",
    "    hdr = fits.getheader(list_of_files[0], 1)\n",
    "    nx = hdr['NAXIS1']\n",
    "    ny = hdr['NAXIS2']\n",
    "    nf = len(list_of_files)\n",
    "    \n",
    "    # Setting up the empty data, rms, and error arrays\n",
    "    data_array_1 = np.empty((nf, ny, nx), dtype=float)\n",
    "    data_array_2 = np.empty((nf, ny, nx), dtype=float)\n",
    "    set_data=fits.getdata(list_of_files[0], 1)\n",
    "    rms_1 = np.zeros(len(list_of_files), dtype=float)\n",
    "    rms_2 = np.zeros(len(list_of_files), dtype=float)\n",
    "    error_array_1 = np.empty((nf, ny, nx), dtype=float)\n",
    "    error_array_2 = np.empty((nf, ny, nx), dtype=float)\n",
    "    total_error_1 = np.zeros_like(set_data, dtype=float)\n",
    "    total_error_2 = np.zeros_like(set_data, dtype=float)\n",
    "    \n",
    "    for i , f in enumerate(list_of_files):\n",
    "        #Read in the data and the DQs from the FITS for both extensions\n",
    "        data_1 = fits.getdata(f, 1)\n",
    "        data_2 = fits.getdata(f, 4)\n",
    "        error_1 = fits.getdata(f, 2)\n",
    "        error_2 = fits.getdata(f, 5)\n",
    "        DQ_1 = fits.getdata(f, 3)\n",
    "        DQ_2 = fits.getdata(f, 6)\n",
    "        \n",
    "        #Set the mask to a boolean array of the same size and shape as the data array\n",
    "        mask_1 = np.zeros_like(data_1, dtype=bool)\n",
    "        mask_2 = np.zeros_like(data_2, dtype=bool)\n",
    "        \n",
    "        #DQ = true because in the masking step a 1 will be masked and 0 allowed,\n",
    "        #so the logic in this step must be reversed.\n",
    "        #Create a mask for the data by setting any pixel with the flag value to True.\n",
    "        mask_1[DQ_1>=2**13] = True\n",
    "        mask_2[DQ_2>=2**13] = True\n",
    "        error_1[(0<DQ_1 & (DQ_1<2**13))] = 0.00001\n",
    "        error_2[(0<DQ_2& (DQ_2<2**13))] = 0.00001\n",
    "        error_1_sq = error_1**2\n",
    "        error_2_sq = error_2**2\n",
    "        \n",
    "        #Mask the data\n",
    "        masked_data_1 = ma.array(data=data_1, mask=mask_1)\n",
    "        masked_data_2 = ma.array(data=data_2, mask=mask_2)\n",
    "        \n",
    "        #Resets the data to an array for stacking\n",
    "        data_array_1[i, :, :] = masked_data_1\n",
    "        rms_1[i] = masked_data_1.std()\n",
    "        data_array_2[i, :, :] = masked_data_2\n",
    "        rms_2[i] = masked_data_2.std()\n",
    "        total_error_1 = total_error_1+(error_1_sq)\n",
    "        total_error_2 = total_error_2+(error_2_sq)\n",
    "        \n",
    "    sr_total_error_1 = np.sqrt(total_error_1)\n",
    "    sr_total_error_2 = np.sqrt(total_error_2)\n",
    "    fin_error_1 = (sr_total_error_1/(float(len(list_of_files))))\n",
    "    fin_error_2 = (sr_total_error_2/(float(len(list_of_files))))\n",
    "    \n",
    "    #Create the median image\n",
    "    image_median_1 = np.median(data_array_1, axis=0)\n",
    "    image_median_2 = np.median(data_array_2, axis=0)\n",
    "    new_hdul = fits.HDUList()\n",
    "    new_hdul.append(fits.ImageHDU(image_median_1))\n",
    "    new_hdul.append(fits.ImageHDU(image_median_2))\n",
    "    new_hdul.writeto(outfile, overwrite=True)\n",
    "    \n",
    "    #Error\n",
    "    new_hdul = fits.HDUList()\n",
    "    new_hdul.append(fits.ImageHDU(fin_error_1))\n",
    "    new_hdul.append(fits.ImageHDU(fin_error_2))\n",
    "    new_hdul.writeto(error_file,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack(paths_year, outfile_year, error_outfile_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-stuff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
